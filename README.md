# IngestÃ£o e Busca SemÃ¢ntica com LangChain e Postgres

Este projeto foi desenvolvido como parte do desafio do MBA em Engenharia de Software com IA. O objetivo Ã© criar uma soluÃ§Ã£o capaz de realizar a ingestÃ£o de documentos PDF em um banco de dados vetorial (PostgreSQL + pgVector) e permitir a realizaÃ§Ã£o de perguntas sobre o conteÃºdo do documento via interface de linha de comando (CLI).

## âœ¨ Funcionalidades

- **IngestÃ£o de PDF:** Processamento e segmentaÃ§Ã£o de arquivos PDF em chunks.
- **Busca SemÃ¢ntica:** RecuperaÃ§Ã£o de informaÃ§Ãµes baseada em similaridade vetorial utilizando `pgVector`.
- **RAG (Retrieval-Augmented Generation):** Respostas geradas por LLM (OpenAI ou Gemini) baseadas estritamente no conteÃºdo do PDF.
- **Interface CLI:** Chat interativo via terminal para consultas.

## ğŸ“‹ PrÃ©-requisitos

Antes de comeÃ§ar, vocÃª precisarÃ¡ ter instalado em sua mÃ¡quina:

- **Python 3.10 ou superior**
- **Docker e Docker Compose**
- **Chave de API:** OpenAI API Key ou Google AI (Gemini) API Key.

## ğŸ“‚ Estrutura do Projeto

```text
â”œâ”€â”€ docker-compose.yml    # ConfiguraÃ§Ã£o do banco de dados PostgreSQL
â”œâ”€â”€ requirements.txt      # DependÃªncias do projeto
â”œâ”€â”€ .env.example          # Template das variÃ¡veis de ambiente
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py         # Script de ingestÃ£o do PDF
â”‚   â”œâ”€â”€ search.py         # LÃ³gica de busca semÃ¢ntica
â”‚   â”œâ”€â”€ chat.py           # CLI para interaÃ§Ã£o com o usuÃ¡rio
â”œâ”€â”€ document.pdf          # PDF para ingestÃ£o (exemplo)
â””â”€â”€ README.md             # InstruÃ§Ãµes de execuÃ§Ã£o
```

## âš™ï¸ ConfiguraÃ§Ã£o

### 1. InstruÃ§Ãµes para o Ambiente Virtual

Crie e ative um ambiente virtual Python:

```bash
python3 -m venv venv
source venv/bin/activate  # No Windows use: venv\Scripts\activate
```

### 2. Instalar DependÃªncias

Com o ambiente virtual ativo, instale os pacotes necessÃ¡rios:

```bash
pip install -r requirements.txt
```

### 3. VariÃ¡veis de Ambiente

Copie o arquivo `.env.example` para `.env`:

```bash
cp .env.example .env
```

### Exemplo de ConfiguraÃ§Ã£o (.env)

Configure as variÃ¡veis conforme sua necessidade:

```env
# Provedor de LLM (Escolha um ou ambos)
GOOGLE_API_KEY=sua_chave_do_gemini
GOOGLE_EMBEDDING_MODEL='models/embedding-001'

OPENAI_API_KEY=sua_chave_da_openai
OPENAI_EMBEDDING_MODEL='text-embedding-3-small'

# Banco de Dados
DATABASE_URL=postgresql+psycopg://langchain:langchain@localhost:6024/langchain
PG_VECTOR_COLLECTION_NAME=pdf_vectors

# Caminho do PDF
PDF_PATH=document.pdf
```

## ğŸ› ï¸ Como Executar

### 1. Subir o Banco de Dados

Utilize o Docker Compose para iniciar o PostgreSQL com pgVector:

```bash
docker compose up -d
```

### 2. Executar a IngestÃ£o do PDF

Processe o documento e armazene os embeddings no banco de dados:

```bash
python src/ingest.py
```

### 3. Iniciar o Chat (Busca)

Inicie a interface de linha de comando para fazer perguntas:

```bash
python src/chat.py
```

## ğŸ’¬ Chat via CLI (Fluxo Completo)

Ao rodar o script de chat, vocÃª poderÃ¡ interagir com a IA. Abaixo estÃ£o exemplos de como o sistema deve se comportar:

### Exemplo de Pergunta no Contexto
**PERGUNTA:** Qual o faturamento da Empresa SuperTechIABrazil?  
**RESPOSTA:** O faturamento foi de 10 milhÃµes de reais.

### Exemplo de Pergunta Fora do Contexto
**PERGUNTA:** Quantos clientes temos em 2024?  
**RESPOSTA:** NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta.

## âš–ï¸ Regras de Resposta

Para garantir a precisÃ£o e fidelidade ao documento, o sistema segue regras rÃ­gidas:

- **Fidelidade ao Contexto:** As respostas sÃ£o geradas baseando-se **apenas** nas informaÃ§Ãµes extraÃ­das do PDF.
- **Conhecimento Externo:** O modelo estÃ¡ proibido de utilizar conhecimentos prÃ©vios ou externos ao documento fornecido.
- **Tratamento de Incerteza:** Caso a resposta nÃ£o esteja presente no PDF, o sistema obrigatoriamente responderÃ¡: *"NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta."*
- **Neutralidade:** O sistema nÃ£o emite opiniÃµes, interpretaÃ§Ãµes ou julgamentos sobre o conteÃºdo.

---

## ğŸ“ Requisitos do Desafio

- **Split:** Chunks de 1000 caracteres com overlap de 150.
- **Busca:** RecuperaÃ§Ã£o dos 10 resultados mais relevantes (k=10).
- **Prompt:** Respostas estritamente baseadas no contexto fornecido, sem uso de conhecimento externo.